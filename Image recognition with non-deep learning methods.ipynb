{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Recognition with Non-Deep Learning Methods\n",
    "\n",
    "In this project, we look at a few non-deep learning methods for prediction so that we can compare them with our deep learning model (see \"Image Recognition with Keras\"). With Keras, we were able to achieve over 98% accuracy on the test set. Let's see how other methods compare.\n",
    "\n",
    "The classifiers we will use are decision tree, random forrests, gradient boosted stumps, logistic regression, and support vector machine. A KNN classifier was attempted, but proved to be too computationally expensive for my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mnist\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The data set is the mnist sample of 60,000 handwritten digits. Each sample is a 28x28 two dimensional array of pixels. Each value in the array is the pixel value and the position in the array represents the position in the actual 2D space where the digit was written.\n",
    "\n",
    "In our data set, the two dimensional data points are flattened to a one dimensional array of 28x28=784 points. The target set denotes what digit the sample represents, 0-9. Thus, there are ten categories for the target set. Using one-hot-encoding, the target set becomes an array of 10 elements.\n",
    "\n",
    "The test set is designed, specifically, so that none of the images was drawn by any of the drawers used in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=mnist.train.images\n",
    "y_train=mnist.train.labels\n",
    "\n",
    "X_valid=mnist.validation.images\n",
    "y_valid=mnist.validation.labels\n",
    "\n",
    "X_test=mnist.test.images\n",
    "y_test=mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes\n",
      "X_train: (55000, 784)\n",
      "y_train: (55000, 10)\n",
      "X_valid: (5000, 784)\n",
      "y_valid: (5000, 10)\n",
      "X_test: (10000, 784),\n",
      "y_test: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#View the shapes of the data sets\n",
    "print(\"Shapes\")\n",
    "print(\"X_train: {}\\ny_train: {}\\nX_valid: {}\\ny_valid: {}\\nX_test: {},\\ny_test: {}\".format(X_train.shape,\n",
    "                                                                                      y_train.shape,\n",
    "                                                                                      X_valid.shape,\n",
    "                                                                                      y_valid.shape,\n",
    "                                                                                      X_test.shape,\n",
    "                                                                                      y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_list=[10,30,50,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees=[DecisionTreeClassifier(random_state=0,max_depth=depth).fit(X_train,y_train) for depth in max_depth_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Max depth: 10\n",
      "Train Accuracy: 0.8777454545454545\n",
      "Validation Accuracy: 0.8402\n",
      "\n",
      "\n",
      "Max depth: 30\n",
      "Train Accuracy: 0.9982727272727273\n",
      "Validation Accuracy: 0.8812\n",
      "\n",
      "\n",
      "Max depth: 50\n",
      "Train Accuracy: 0.9999818181818182\n",
      "Validation Accuracy: 0.8752\n",
      "\n",
      "\n",
      "Max depth: 100\n",
      "Train Accuracy: 1.0\n",
      "Validation Accuracy: 0.873\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(max_depth_list)):\n",
    "    print(\"\\n\\nMax depth: {}\".format(max_depth_list[i]))\n",
    "    print(\"Train Accuracy: {}\\nValidation Accuracy: {}\".format(trees[i].score(X_train,y_train),\n",
    "                                                               trees[i].score(X_valid,y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we may be overfitting somewhere arround max_depth=30 and above. Let's try a few more values below about 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_list2=[5,10,15,20,25,30,35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees2=[DecisionTreeClassifier(random_state=0,max_depth=depth).fit(X_train,y_train) for depth in max_depth_list2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores2=[tree.score(X_train,y_train) for tree in trees2]\n",
    "valid_scores2=[tree.score(X_valid,y_valid) for tree in trees2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b4de4af7b8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b4ddbb92b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(max_depth_list2,train_scores2,\"-\",color=\"red\",label=\"Train\")\n",
    "plt.plot(max_depth_list2,valid_scores2,\"-\",color=\"blue\",label=\"Validation\")\n",
    "plt.xlabel(\"Max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that overfitting occurs arround max_depth of 10. Let's fit a few more models around 10. In any case, we see that our best validation accuracy is significantly less than what we can achieve with a deep learning model. Let's choose depth of 10 as our model determine the accuracy on the test set. \n",
    "\n",
    "We also note that overfitting is a significant problem with the decision tree. Perhaps our next step should be to look at random forrests and boosted ensembles of tree stumps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84489999999999998"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees2[1].score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n",
    "As we observed previously, a single tree is prone to overfitting. To avoid this, we can consider a random forrest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest=RandomForestClassifier(n_estimators=5,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=5, n_jobs=1,\n",
       "            oob_score=False, random_state=2, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9861272727272727\n",
      "Validation Accuracy: 0.8814\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: {}\\nValidation Accuracy: {}\".format(forest.score(X_train,y_train),\n",
    "                                                          forest.score(X_valid,y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have achieved better accuracy than the single tree, as expected, but we might still be over fitting and we are still at a much lower accuracy than the deep learning model. Let's adjust our parameters to see how high we can get our accuracy before moving on to boosted stumps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators=[5,20,50,100,500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "forests=[RandomForestClassifier(n_estimators=estimator,random_state=2).fit(X_train,y_train) for estimator in estimators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_forest=[forest.score(X_train,y_train) for forest in forests]\n",
    "validation_score_forest=[forest.score(X_valid,y_valid) for forest in forests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b48036ef28>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b480334630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(estimators,train_score_forest,\"-\",color=\"red\",label=\"Train\")\n",
    "plt.plot(estimators,validation_score_forest,\"-\",color=\"blue\",label=\"Validation\")\n",
    "plt.xlabel(\"Number of Estimators\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our accuracy maxed out at around 100 estimators. It also looks like we are overfitting at this point. Let's choose the 100 estimator random forrest and test our accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90210000000000001"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forests[3].score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "90% accuracy is better than with the single tree but not nearly as good as the deep learning neural network. Let's try gradient boosted stumps to see if we can avoid the overfitting we see with the random forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Stumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's begin with the default setting of 100 trees, maximum depth 3 and learning rate of 0.1\n",
    "gbt=GradientBoostingClassifier(random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can fit our model, we need to reverse the one-hot-encoding. We will do this by creating three different functions, which we can apply to the train, valid and test sets (as pandas data frames), respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df=pd.DataFrame(y_train)\n",
    "y_valid_df=pd.DataFrame(y_valid)\n",
    "y_test_df=pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function that can be applied to the y_train dataframe to undue the one hot encoding\n",
    "def get_class_train(row):\n",
    "    for column in y_train_df.columns:\n",
    "        if int(row[column])==1:\n",
    "            return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function that can be applied to the y_valid dataframe to undue the one hot encoding\n",
    "def get_class_valid(row):\n",
    "    for column in y_valid_df.columns:\n",
    "        if int(row[column])==1:\n",
    "            return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function that can be applied to the y_test dataframe to undue the one hot encoding\n",
    "def get_class_test(row):\n",
    "    for column in y_test_df.columns:\n",
    "        if int(row[column])==1:\n",
    "            return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "y_train_classes=pd.DataFrame(y_train).apply(get_class_train,axis=1)\n",
    "y_valid_classes=pd.DataFrame(y_valid).apply(get_class_valid,axis=1)\n",
    "y_test_classes=pd.DataFrame(y_test).apply(get_class_valid,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=2, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt.fit(X_train,y_train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9619090909090909\n",
      "Validation Accuracy: 0.9472\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: {}\\nValidation Accuracy: {}\".format(gbt.score(X_train,y_train_classes),\n",
    "                                                           gbt.score(X_valid,y_valid_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's adjust the learning rate to increase complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rates=[0.5,1]\n",
    "gbt_lr_list=[GradientBoostingClassifier(learning_rate=lr,random_state=2).fit(X_train,y_train_classes) for lr in learn_rates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9915454545454545\n",
      "Validation Accuracy: 0.9546\n",
      "Train Accuracy: 0.9617818181818182\n",
      "Validation Accuracy: 0.925\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: {}\\nValidation Accuracy: {}\".format(gbt_lr_list[0].score(X_train,y_train_classes),\n",
    "                                                           gbt_lr_list[0].score(X_valid,y_valid_classes)))\n",
    "print(\"Train Accuracy: {}\\nValidation Accuracy: {}\".format(gbt_lr_list[1].score(X_train,y_train_classes),\n",
    "                                                           gbt_lr_list[1].score(X_valid,y_valid_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt3=GradientBoostingClassifier(random_state=2,max_depth=1,n_estimators=300).fit(X_train,y_train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9045818181818182\n",
      "Validation Accuracy: 0.9048\n"
     ]
    }
   ],
   "source": [
    "#Find the accuracy of the latest gbt\n",
    "print(\"Train Accuracy: {}\\nValidation Accuracy: {}\".format(gbt3.score(X_train,y_train_classes),\n",
    "                                                           gbt3.score(X_valid,y_valid_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This appears to be underfit. Let's try 400 estimators with max_depth 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt4=GradientBoostingClassifier(random_state=2,max_depth=2,n_estimators=400).fit(X_train,y_train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9737818181818182\n",
      "Validation Accuracy: 0.9572\n"
     ]
    }
   ],
   "source": [
    "#Find the accuracy of gbt4\n",
    "print(\"Train Accuracy: {}\\nValidation Accuracy: {}\".format(gbt4.score(X_train,y_train_classes),\n",
    "                                                           gbt4.score(X_valid,y_valid_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that gbt4 may not be overfit and that increasing the complexity can result in greater accuracy. However, due to the large amounts of time it takes to train these models, I will stop here. I will choose gbt4 as the best performing gradient boosted tree and check it's performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of gbt4: 0.9545\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy of gbt4: {}\".format(gbt4.score(X_test,y_test_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST website reports literature values of the error to be 7.7 for boosted stumps, 1.26 for products of boosted stumps, and 1.53 for boosted trees having 17 leaves. We see that our results are better than the boosted stumps, but not quite as good as the other two methods.\n",
    "\n",
    "With cloud computing, I could have reasonably conducted a more thorough parameter search and acquired better results. However, the deep learning method can also achieve these results in very little time on my laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classifiers\n",
    "\n",
    "Next, let's try logistic regression (without preprocessing or feature engineering) and a support vector machine. Due to the large number of features (748), manual feature engineering would be a time consuming method. However, I do imagine that relationships would exist amongst the features. Thus, I suspect a SVM would achieve better results than the logistic regression, but let us compare and contrast both methods.\n",
    "\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the default setting of C=1.\n",
    "logreg=LogisticRegression(random_state=2).fit(X_train,y_train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.9281090909090909\n",
      "Validation Accuracy: 0.921\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy:{}\\nValidation Accuracy: {}\".format(logreg.score(X_train,y_train_classes),\n",
    "                                                         logreg.score(X_valid,y_valid_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we are underfitting. The parameter C is the inverse of the regularization. Thus, increasing C, will decrease the regularization, which should correspond to a more complex model. Let's try fitting a couple more models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_vals=[100,200]\n",
    "logreg_models=[LogisticRegression(random_state=2,C=C).fit(X_train,y_train_classes) for C in C_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Accuracy:0.9318\n",
      "Validation Accuracy: 0.919\n",
      "\n",
      "Train Accuracy:0.9320363636363637\n",
      "Validation Accuracy: 0.9184\n"
     ]
    }
   ],
   "source": [
    "for model in logreg_models:\n",
    "    print(\"\\nTrain Accuracy:{}\\nValidation Accuracy: {}\".format(model.score(X_train,y_train_classes),\n",
    "                                                             model.score(X_valid,y_valid_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try again with higher C_vals\n",
    "C_vals2=[500,1000,1e40]\n",
    "logreg_models2=[LogisticRegression(random_state=2,C=C).fit(X_train,y_train_classes) for C in C_vals2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Accuracy:0.9322363636363636\n",
      "Validation Accuracy: 0.918\n",
      "\n",
      "Train Accuracy:0.9322727272727273\n",
      "Validation Accuracy: 0.9168\n",
      "\n",
      "Train Accuracy:0.9323454545454546\n",
      "Validation Accuracy: 0.9168\n"
     ]
    }
   ],
   "source": [
    "for model in logreg_models2:\n",
    "    print(\"\\nTrain Accuracy:{}\\nValidation Accuracy: {}\".format(model.score(X_train,y_train_classes),\n",
    "                                                             model.score(X_valid,y_valid_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It still appears that we are underfitting, but it is not due to regularization. Let us examine the accuracy on the test set and then move on to the SVM, which might provide us with a more complex and, therefore, more accurate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9198\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy: {}\".format(logreg.score(X_test,y_test_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we have not achieved as high of an accuracy with logistic regression as we have with other models, our roughly 8% error is less than the 12% error that MNIST reports for a 1 layer NN without preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model1=SVC().fit(X_train,y_train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracty: 0.9418363636363636\n",
      "Validation Accuracy: 0.9468\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracty: {}\\nValidation Accuracy: {}\".format(svm_model1.score(X_train,y_train_classes),\n",
    "                                                           svm_model1.score(X_valid,y_valid_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Increase complexity\n",
    "svm_model2=SVC(C=500).fit(X_train,y_train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracty: 0.9997454545454545\n",
      "Validation Accuracy: 0.9758\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracty: {}\\nValidation Accuracy: {}\".format(svm_model2.score(X_train,y_train_classes),\n",
    "                                                           svm_model2.score(X_valid,y_valid_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a good fit, but let's see if we can get a higher validation accuracy with a slightly less complex model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model3=SVC(C=300).fit(X_train,y_train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracty: 0.9992727272727273\n",
      "Validation Accuracy: 0.9762\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracty: {}\\nValidation Accuracy: {}\".format(svm_model3.score(X_train,y_train_classes),\n",
    "                                                           svm_model3.score(X_valid,y_valid_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model4=SVC(C=100).fit(X_train,y_train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracty: 0.9945818181818182\n",
      "Validation Accuracy: 0.9764\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracty: {}\\nValidation Accuracy: {}\".format(svm_model4.score(X_train,y_train_classes),\n",
    "                                                           svm_model4.score(X_valid,y_valid_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model5=SVC(C=50).fit(X_train,y_train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracty: 0.9881090909090909\n",
      "Validation Accuracy: 0.9754\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracty: {}\\nValidation Accuracy: {}\".format(svm_model5.score(X_train,y_train_classes),\n",
    "                                                           svm_model5.score(X_valid,y_valid_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose the last model as our model of choice and score our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9722\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy: {}\".format(svm_model5.score(X_test,y_test_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST website reports an error of 1.4%. We didn't do quite as well. However, we did improve our score compared with the logistic regression, as expected, and overall, this is a great score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "All methods tested, had accuracies that ranged from 84% to 97%. The single decision tree had a test accuracy of 84%. The random forest had improved results of 90%. Using gradient boosted stumps, we achieved an accuracy of 95%. The MNIST website reports a literature result with an error of 7.7% for the gradient boosted stump.\n",
    "\n",
    "Logistic regression without preprocessing or feature engineering resulted in 92% accuracy. MNIST doesn't report a score for logistic regression, however, they do report an error of 12% for a single layer neural network. Thus, I would assume that our 92% accuracy is up to industry standard.\n",
    "\n",
    "The support vector machine achieved a higher accuracy, as was expected. We achieved 97% accuracy, which is close to the 98% accuracy we achieved with the deep learning neural network. This is not quite as good as the 98.6% accuracy MNIST reports for the SVM, Gaussian kernal, no preprocessing score.\n",
    "\n",
    "Although these scores are similar to what has been achieved before, for the respective models, MNIST reports models that have achieved greater than 99% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
